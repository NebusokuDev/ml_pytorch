{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## データローダーの実装",
   "id": "1378ba56a653cdea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import zipfile\n",
    "from logging import Logger, getLogger\n",
    "from os import mkdir\n",
    "from typing import Callable\n",
    "from urllib.parse import urlparse\n",
    "from zipfile import BadZipFile\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from jupyterthemes.stylefx import check_directories\n",
    "from requests import Response\n",
    "from torch import no_grad\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms.v2 import ToTensor, RandomHorizontalFlip\n",
    "from tqdm import tqdm\n",
    "\n",
    "KIB = 2 ** 10\n",
    "\n",
    "\n",
    "class Downloader:\n",
    "    \"\"\"\n",
    "    指定されたURLからデータセットをダウンロードし、ZIPファイルを解凍するクラス。\n",
    "\n",
    "    :param root: ダウンロード先のルートディレクトリ。\n",
    "    :param url: ダウンロードするURLまたはURLを返す関数。\n",
    "    :param overwrite: 既存のファイルを上書きするかどうか（デフォルトはFalse）。\n",
    "    :param zip_filename: ZIPファイルの名前（指定がない場合はURLから取得）。\n",
    "    :param logger: ロギング用のLoggerオブジェクト（指定がない場合はデフォルトのLoggerを使用）。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root: str, url: str | Callable[[], str] = None, overwrite: bool = False,\n",
    "                 zip_filename: str = None,\n",
    "                 logger: Logger = None):\n",
    "        \"\"\"\n",
    "        Downloaderのコンストラクタ。\n",
    "\n",
    "        :param root: ダウンロード先のルートディレクトリ。\n",
    "        :param url: ダウンロードするURLまたはURLを返す関数。\n",
    "        :param overwrite: 既存のファイルを上書きするかどうか（デフォルトはFalse）。\n",
    "        :param zip_filename: ZIPファイルの名前（指定がない場合はURLから取得）。\n",
    "        :param logger: ロギング用のLoggerオブジェクト（指定がない場合はデフォルトのLoggerを使用）。\n",
    "        \"\"\"\n",
    "        self._root = os.path.normpath(root)\n",
    "\n",
    "        if isinstance(url, Callable):\n",
    "            self.url = url()\n",
    "        else:\n",
    "            self.url = url\n",
    "\n",
    "        self.zip_filename = zip_filename or os.path.basename(urlparse(self.url).path)  # URLからファイル名を取得\n",
    "        self.zip_path = os.path.join(self._root, self.zip_filename)\n",
    "        self.extract_path = os.path.splitext(self.zip_path)[0]\n",
    "        self.overwrite = overwrite\n",
    "        self.logger = logger or getLogger(__name__)\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"データセットをダウンロードする。\n",
    "\n",
    "        既にデータセットがダウンロードされている場合、overwriteがFalseの場合はダウンロードをスキップします。\n",
    "        \"\"\"\n",
    "        if self.is_downloaded() and not self.overwrite:\n",
    "            print(f\"Dataset already exists at {self.zip_path}, skipping download.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Downloading dataset from {self.url}...\")\n",
    "\n",
    "        try:\n",
    "            response = self.request(self.url)\n",
    "            self.save_response_content(response, self.zip_path)\n",
    "\n",
    "            print(\"\\nDownload completed.\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error during download: {e}\")\n",
    "\n",
    "        except zipfile.BadZipFile:\n",
    "            print(\"Error: Bad zip file.\")\n",
    "\n",
    "    def request(self, url):\n",
    "        \"\"\"指定されたURLにGETリクエストを送り、レスポンスを返す。\n",
    "\n",
    "        :param url: リクエストするURL。\n",
    "        :return: リクエストの結果得られたレスポンスオブジェクト。\n",
    "        \"\"\"\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()  # HTTPエラーを確認\n",
    "        return response\n",
    "\n",
    "    def save_response_content(self, response: Response, destination, chunk_size: int = 100 * KIB):\n",
    "        \"\"\"レスポンスのコンテンツを指定されたファイルに保存する。\n",
    "\n",
    "        :param response: 保存するためのレスポンスオブジェクト。\n",
    "        :param destination: 保存先ファイルのパス。\n",
    "        :param chunk_size: 保存時のチャンクサイズ（デフォルトは100KiB）。\n",
    "        \"\"\"\n",
    "        if not exists(self.root):\n",
    "            mkdir(self.root)\n",
    "\n",
    "        with open(destination, \"wb\") as f:\n",
    "            for chunk in tqdm(response.iter_content(chunk_size=chunk_size)):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "    def extract(self):\n",
    "        \"\"\"ZIPファイルを解凍し、重複したルートフォルダがある場合はまとめる。\n",
    "\n",
    "        解凍先のディレクトリが既に存在する場合、その内容は保持されます。\n",
    "        \"\"\"\n",
    "        print(f\"Unzipping {self.zip_path}...\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(self.zip_path, 'r') as zip_ref:\n",
    "                # ZIPファイルのトップレベルのフォルダを確認\n",
    "                top_level_dirs = {os.path.normpath(x).split(os.sep)[0] for x in zip_ref.namelist()}\n",
    "\n",
    "                if len(top_level_dirs) == 1:\n",
    "                    # トップレベルに1つのディレクトリだけある場合\n",
    "                    top_level_dir = next(iter(top_level_dirs))\n",
    "                    self.extract_path = os.path.join(self._root, top_level_dir)\n",
    "                    print(f\"Extracting into {self.extract_path}...\")\n",
    "\n",
    "                total_files = len(zip_ref.namelist())\n",
    "                with tqdm(total=total_files, unit='file') as progress:\n",
    "                    for file in zip_ref.namelist():\n",
    "                        destination = self._root if len(top_level_dirs) == 1 else self.extract_path\n",
    "                        zip_ref.extract(file, destination)\n",
    "                        progress.update(1)\n",
    "        except BadZipFile:\n",
    "            print(\"Error: Bad zip file, extraction failed.\")\n",
    "\n",
    "        print(f\"Extracted to {self._root}.\")\n",
    "\n",
    "    @property\n",
    "    def root(self):\n",
    "        \"\"\"ダウンロード先のルートディレクトリを取得する。\"\"\"\n",
    "        return self._root\n",
    "\n",
    "    def is_downloaded(self):\n",
    "        \"\"\"ZIPファイルがダウンロードされているかどうかを確認する。\n",
    "\n",
    "        :return: ZIPファイルが存在する場合はTrue、それ以外はFalse。\n",
    "        \"\"\"\n",
    "        return os.path.exists(self.zip_path)\n",
    "\n",
    "    def is_extracted(self):\n",
    "        \"\"\"データセットが解凍されているかどうかを確認する。\n",
    "\n",
    "        :return: 解凍先が存在する場合はTrue、それ以外はFalse。\n",
    "        \"\"\"\n",
    "        return os.path.exists(self.extract_path)\n",
    "\n",
    "    def __call__(self, on_complete: Callable = None):\n",
    "        \"\"\"ダウンロードおよび解凍を実行する。\n",
    "\n",
    "        :param on_complete: 処理完了後に呼び出す関数（オプション）。\n",
    "        \"\"\"\n",
    "        if self.overwrite or not self.is_downloaded():\n",
    "            self.download()\n",
    "        else:\n",
    "            print(\"Dataset exists and 'overwrite' is False. No download.\")\n",
    "\n",
    "        if self.overwrite or not self.is_extracted():\n",
    "            self.extract()\n",
    "        else:\n",
    "            print(\"Dataset exists and 'overwrite' is False. No extract.\")\n",
    "\n",
    "        if on_complete is not None:\n",
    "            on_complete()"
   ],
   "id": "4a618cb00c105aef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "from datasets.downloader import Downloader\n",
    "\n",
    "\n",
    "class Cat2000(Dataset):\n",
    "    def __init__(self, categories: Optional[list[str]] = None,\n",
    "                 image_transform: Optional = None,\n",
    "                 map_transform: Optional = None,\n",
    "                 downloader: Optional[Downloader] = None,\n",
    "                 ):\n",
    "        if categories is None:\n",
    "            categories = [\"*\"]\n",
    "        self.categories = categories\n",
    "        self.image_transform = image_transform\n",
    "        self.map_transform = map_transform\n",
    "        self.downloader = downloader or Downloader(\"./data\", \"http://saliency.mit.edu/trainSet.zip\")\n",
    "        self.dataset_path = os.path.join(self.downloader.root, \"trainSet\", \"Stimuli\")\n",
    "\n",
    "        # 画像とマップのペアを取得\n",
    "        self.image_map_pair_cache = []\n",
    "        self.downloader(on_complete=self.cache_image_map_paths)\n",
    "\n",
    "    def cache_image_map_paths(self):\n",
    "        self.image_map_pair_cache = []\n",
    "\n",
    "        # categoriesにワイルドカードが含まれている場合、全カテゴリディレクトリを展開\n",
    "        if \"*\" in self.categories:\n",
    "            expanded_categories = [d for d in glob.glob(os.path.join(self.dataset_path, \"*\")) if os.path.isdir(d)]\n",
    "        else:\n",
    "            expanded_categories = [os.path.join(self.dataset_path, category) for category in self.categories]\n",
    "\n",
    "        # 展開したカテゴリディレクトリごとに処理を行う\n",
    "        for category_path in expanded_categories:\n",
    "            # 画像ファイルのパスを取得\n",
    "            image_paths = glob.glob(os.path.join(category_path, \"*.jpg\"))\n",
    "\n",
    "            for image_path in image_paths:\n",
    "                base_name = os.path.basename(image_path)\n",
    "                map_name = base_name.replace(\".jpg\", \"_SaliencyMap.jpg\")\n",
    "                map_path = os.path.join(category_path, \"Output\", map_name)\n",
    "\n",
    "                if os.path.exists(map_path):\n",
    "                    self.image_map_pair_cache.append((image_path, map_path))\n",
    "                else:\n",
    "                    print(f\"Warning: No corresponding map found for {map_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_map_pair_cache)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image_path, map_path = self.image_map_pair_cache[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        map_image = Image.open(map_path).convert(\"RGB\")\n",
    "\n",
    "        if self.image_transform is not None:\n",
    "            image = self.image_transform(image)\n",
    "\n",
    "            if self.map_transform is not None:\n",
    "                map_image = self.map_transform(map_image)\n",
    "            else:\n",
    "                map_image = self.image_transform(map_image)\n",
    "\n",
    "        return image, map_image\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"\\n\".join(\n",
    "            f\"image: {Image.open(pair[0]).size}, map: {Image.open(pair[1]).size}\" for pair in self.image_map_pair_cache)\n"
   ],
   "id": "6735eb0e39ba5932",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import glob\n",
    "from os import path\n",
    "from typing import Optional, Callable\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from datasets.downloader import Downloader\n",
    "\n",
    "\n",
    "class SALICONDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 val_mode: bool = False,\n",
    "                 image_transform: Optional[Callable] = None,\n",
    "                 map_transform: Optional[Callable] = None,\n",
    "                 images_downloader: Optional[Downloader] = None,\n",
    "                 map_downloader: Optional[Downloader] = None,\n",
    "                 ):\n",
    "\n",
    "        self.categories = \"val\" if val_mode else \"train\"\n",
    "\n",
    "        self.image_transform = image_transform\n",
    "        self.map_transform = map_transform\n",
    "\n",
    "        self.images_downloader = images_downloader or Downloader(\"./data/salicon\", \"\", zip_filename=\"images.zip\",\n",
    "                                                                 overwrite=False)\n",
    "        self.maps_downloader = map_downloader or Downloader(\"./data/salicon\", \"\", zip_filename=\"maps.zip\",\n",
    "                                                            overwrite=False)\n",
    "\n",
    "        self.images_downloader()\n",
    "        self.maps_downloader()\n",
    "\n",
    "        # 画像とマップのペアを取得\n",
    "        self.image_map_pair_cache = []\n",
    "        self.cache_image_map_paths()\n",
    "\n",
    "    def cache_image_map_paths(self):\n",
    "        for category in self.categories:\n",
    "            images_dir = self.images_downloader.extract_path\n",
    "            maps_dir = self.maps_downloader.extract_path\n",
    "\n",
    "            images_path_list = sorted(glob.glob(path.join(images_dir, category, \"*.jpg\")))\n",
    "            maps_path_list = sorted(glob.glob(path.join(maps_dir, category, \"*.png\")))\n",
    "\n",
    "            # ペアリング\n",
    "            for img_path, map_path in zip(images_path_list, maps_path_list):\n",
    "                if path.basename(img_path) == path.basename(map_path).replace(\".png\", \".jpg\"):\n",
    "                    self.image_map_pair_cache.append((img_path, map_path))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_map_pair_cache)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_path, map_path = self.image_map_pair_cache[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        map_image = Image.open(map_path).convert(\"RGB\")\n",
    "\n",
    "        if self.image_transform is not None:\n",
    "            image = self.image_transform(image)\n",
    "\n",
    "            if self.map_transform is not None:\n",
    "                map_image = self.map_transform(map_image)\n",
    "            else:\n",
    "                map_image = self.image_transform(map_image)\n",
    "\n",
    "        return image, map_image\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"\\n\".join(\n",
    "            f\"image: {Image.open(pair[0]).size}, map: {Image.open(pair[1]).size}\" for pair in self.image_map_pair_cache)\n"
   ],
   "id": "d6ae05a98ab1f2cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## モデルの実装",
   "id": "ad64cc57ad529323"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T11:29:07.511702Z",
     "start_time": "2024-11-04T11:29:05.312083Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "from torch.nn import Module\n",
    "from torchvision.models import vgg16\n",
    "\n",
    "\n",
    "class DecoderBlock(Module):\n",
    "    def __init__(self, in_channels=512, out_channels=512):\n",
    "        super().__init__()\n",
    "        self.module = Sequential(\n",
    "            Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            LeakyReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "class Generator(Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.encoder1 = vgg16(pretrained=pretrained).features[:17]\n",
    "        self.encoder_last = vgg16(pretrained=pretrained).features[17:-1]\n",
    "        self.decoder = Sequential(\n",
    "            DecoderBlock(512, 512),\n",
    "            DecoderBlock(512, 512),\n",
    "            DecoderBlock(512, 512),\n",
    "            Upsample(scale_factor=2),\n",
    "\n",
    "            DecoderBlock(512, 512),\n",
    "            DecoderBlock(512, 512),\n",
    "            DecoderBlock(512, 512),\n",
    "\n",
    "            Upsample(scale_factor=2),\n",
    "\n",
    "            DecoderBlock(512, 256),\n",
    "            DecoderBlock(256, 256),\n",
    "            DecoderBlock(256, 256),\n",
    "\n",
    "            Upsample(scale_factor=2),\n",
    "\n",
    "            DecoderBlock(256, 128),\n",
    "            DecoderBlock(128, 128),\n",
    "\n",
    "            Upsample(scale_factor=2),\n",
    "            DecoderBlock(128, 64),\n",
    "            DecoderBlock(64, 64),\n",
    "        )\n",
    "        self.output = Sequential(\n",
    "            Conv2d(64, 1, 1, padding=0),\n",
    "            Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder1(x)\n",
    "        x = self.encoder_last(x)\n",
    "        x = self.decoder(x)\n",
    "        return self.output(x)"
   ],
   "id": "54a588cf448ae4cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.nn import Module, Sequential, Conv2d, LeakyReLU, Upsample, Sigmoid, MaxPool2d, Tanh, Linear\n",
    "\n",
    "\n",
    "class Discriminator(Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.main = Sequential(\n",
    "            Conv2d(4, 3, 1, padding=1),\n",
    "            LeakyReLU(inplace=True),\n",
    "            Conv2d(3, 32, 3, padding=1),\n",
    "            LeakyReLU(inplace=True),\n",
    "            MaxPool2d(2, stride=2),\n",
    "            Conv2d(32, 64, 3, padding=1),\n",
    "            LeakyReLU(inplace=True),\n",
    "            Conv2d(64, 64, 3, padding=1),\n",
    "            LeakyReLU(inplace=True),\n",
    "            MaxPool2d(2, stride=2),\n",
    "            Conv2d(64, 64, 3, padding=1),\n",
    "            LeakyReLU(inplace=True),\n",
    "            Conv2d(64, 64, 3, padding=1),\n",
    "            LeakyReLU(inplace=True),\n",
    "            MaxPool2d(2, stride=2))\n",
    "\n",
    "        self.classifier = Sequential(\n",
    "            Linear(64 * 32 * 24, 100, bias=True),\n",
    "            Tanh(),\n",
    "            Linear(100, 2, bias=True),\n",
    "            Tanh(),\n",
    "            Linear(2, 1, bias=True),\n",
    "            Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ],
   "id": "2a43797a7d994f3f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ユーティリティ関数",
   "id": "31ed7a6f2cbe0fb9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_timestamp(date_format=\"{0:%Y%m%d-%H%M%S}\"):\n",
    "    return date_format.format(datetime.now())"
   ],
   "id": "f70a610be0cfb410"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def generate_map(generator: Module, transform, image):\n",
    "    with torch.no_grad():\n",
    "        image = transform(image)\n",
    "        saliency_map = generator(image)\n",
    "        saliency_map = np.array(saliency_map.cpu())[0, 0]\n",
    "\n",
    "    saliency_map = saliency_map / saliency_map.sum()\n",
    "    saliency_map = (())"
   ],
   "id": "6c4be839b6b991a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### トレーニングの実装",
   "id": "c2f5853354be85bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch.nn import Module, BCELoss\n",
    "from torch.autograd import Variable, no_grad\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Generatorのトレーニングステップ\n",
    "def generator_train_step(generator, discriminator, valid, image, real_map, criterion, optimizer, alpha=0.005):\n",
    "    optimizer.zero_grad()\n",
    "    generated_map = generator(image)\n",
    "\n",
    "    # Discriminatorへの入力用に元の画像と生成したSaliency Mapを結合して4チャンネルの配列を作る\n",
    "    fake_d_input = torch.cat((image, generated_map.detach()), 1)\n",
    "\n",
    "    # Generatorの損失関数を計算\n",
    "    g_loss1 = criterion(generated_map, real_map)\n",
    "    g_loss2 = criterion(discriminator(fake_d_input), valid)\n",
    "    loss = alpha * g_loss1 + g_loss2\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), generated_map\n",
    "\n",
    "\n",
    "# Discriminatorのトレーニングステップ\n",
    "def discriminator_train_step(discriminator, fake, valid, image, fake_map, real_map, criterion, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Discriminatorへの入力用に元の画像と正解データのSaliency Mapを結合して4チャンネルの配列を作る\n",
    "    real_d_input = torch.cat((image, real_map), 1)\n",
    "    fake_d_input = torch.cat((image, fake_map), 1)\n",
    "\n",
    "    # Discriminatorの損失関数を計算\n",
    "    real_loss = criterion(discriminator(real_d_input), valid)\n",
    "    fake_loss = criterion(discriminator(fake_d_input), fake)\n",
    "    loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "# トレーニングループ\n",
    "def training(generator, discriminator, dataloader, criterion, generator_optimizer, discriminator_optimizer, device):\n",
    "    discriminator_total_loss = 0\n",
    "    generator_total_loss = 0\n",
    "\n",
    "    check_directories()\n",
    "\n",
    "    for batch_index, (image, real_map) in enumerate(dataloader):\n",
    "        valid = Variable(torch.FloatTensor(image.shape[0], 1).fill_(1.0), requires_grad=False).to(device)\n",
    "        fake = Variable(torch.FloatTensor(image.shape[0], 1).fill_(0.0), requires_grad=False).to(device)\n",
    "        image, real_map = image.to(device), real_map.to(device)\n",
    "\n",
    "        # Generator と Discriminator の学習を交互に実行\n",
    "        if batch_index % 2 == 0:\n",
    "            g_loss, fake_map = generator_train_step(generator, discriminator, valid, image, real_map, criterion,\n",
    "                                                    generator_optimizer)\n",
    "            generator_total_loss += g_loss\n",
    "            print(f\"Generator Loss: {g_loss:.4f}\")\n",
    "        else:\n",
    "            d_loss = discriminator_train_step(discriminator, fake, valid, image, fake_map, real_map, criterion,\n",
    "                                              discriminator_optimizer)\n",
    "            discriminator_total_loss += d_loss\n",
    "            print(f\"Discriminator Loss: {d_loss:.4f}\")\n",
    "\n",
    "\n",
    "# 重みとログの保存\n",
    "def save_report(start_time_stamp, generator, discriminator, epoch, save_dir=\"./logs\"):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    generator_save_path = f'{os.path.join(save_dir, f\"{start_time_stamp}_generator_epoch{epoch}\")}.pkl'\n",
    "    discriminator_save_path = f'{os.path.join(save_dir, f\"{start_time_stamp}_discriminator_epoch{epoch}\")}.pkl'\n",
    "    torch.save(generator.state_dict(), generator_save_path)\n",
    "    torch.save(discriminator.state_dict(), discriminator_save_path)\n",
    "\n",
    "\n",
    "# テスト（検証）フェーズ\n",
    "def testing(generator, discriminator, dataloader: DataLoader, criterion, device, show_stride=100):\n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"validation\")\n",
    "        for i, (image, _) in enumerate(dataloader):\n",
    "            image = image.to(device)\n",
    "            generated = generator(image)\n",
    "            generated_np = np.array(generated.data.cpu())[0, 0]\n",
    "\n",
    "            plt.imshow(np.array(image[0].cpu()).transpose(1, 2, 0))\n",
    "            plt.show()\n",
    "            plt.imshow(generated_np)\n",
    "            plt.show()\n",
    "            if i == 1:\n",
    "                break\n",
    "\n",
    "\n",
    "# 学習と検証のメインループ\n",
    "def run(generator, discriminator, train_dataloader, test_dataloader, criterion, generator_optimizer,\n",
    "        discriminator_optimizer, device, epochs=120):\n",
    "    time_stamp = get_timestamp()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"--- Epoch {epoch + 1}/{epochs} - training start ---\")\n",
    "        training(generator, discriminator, train_dataloader, criterion, generator_optimizer, discriminator_optimizer,\n",
    "                 device)\n",
    "\n",
    "        if (epoch % 5 == 0) or (epoch == epochs - 1):\n",
    "            save_report(time_stamp, generator, discriminator, epoch)\n",
    "\n",
    "        print(f\"--- Epoch {epoch + 1}/{epochs} - testing start ---\")\n",
    "        testing(generator, discriminator, test_dataloader, criterion, device)\n"
   ],
   "id": "45ef0bc4740adefc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### セットアップ と実行",
   "id": "828c1a7e3e44e482"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from torch.nn import BCELoss\n",
    "from torch.optim import Adagrad\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 3 * learning_rate\n",
    "epochs = 120\n",
    "\n",
    "# データの前処理\n",
    "image_transform = Compose([Resize((192, 256)), ToTensor()])\n",
    "map_transform = Compose([Resize((192, 256)), ToTensor(), Normalize([0.5], [0.5])])\n",
    "\n",
    "# データセットの読み込み\n",
    "salicon_train = SALICONDataset(image_transform=image_transform, map_transform=map_transform)\n",
    "salicon_test = SALICONDataset(val_mode=True, image_transform=image_transform, map_transform=map_transform)\n",
    "\n",
    "# データローダーの作成\n",
    "train_dataloader = DataLoader(salicon_train, batch_size=32, shuffle=True, pin_memory=True, num_workers=4)\n",
    "test_dataloader = DataLoader(salicon_test, batch_size=8, shuffle=False, pin_memory=True, num_workers=4)\n",
    "\n",
    "# モデルの定義\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# 損失関数とオプティマイザの設定\n",
    "criterion = BCELoss()\n",
    "generator_optimizer = Adagrad([\n",
    "    {'params': generator.encoder_last.parameters()},\n",
    "    {'params': generator.decoder.parameters()}\n",
    "], lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "discriminator_optimizer = Adagrad(discriminator.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# デバイスの設定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 学習と検証の実行\n",
    "run(generator, discriminator, train_dataloader, test_dataloader, criterion, generator_optimizer,\n",
    "    discriminator_optimizer, device, epochs)\n"
   ],
   "id": "b2aae1c3dd4569db"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
